{"node_id": "22ef5d7e", "title": "6. Implement human-in-the-loop review", "path": "sql-agent > Build a custom SQL agent > 6. Implement human-in-the-loop review", "content": "It can be prudent to check the agent's SQL queries before they are executed for any unintended actions or inefficiencies.\n\nHere we leverage LangGraph's [human-in-the-loop](/oss/python/langgraph/interrupts) features to pause the run before executing a SQL query and wait for human review. Using LangGraph's [persistence layer](/oss/python/langgraph/persistence), we can pause the run indefinitely (or at least as long as the persistence layer is alive).\n\nLet's wrap the `sql_db_query` tool in a node that receives human input. We can implement this using the [interrupt](/oss/python/langgraph/interrupts) function. Below, we allow for input to approve the tool call, edit its arguments, or provide user feedback.\n\n```python  theme={null}\nfrom langchain_core.runnables import RunnableConfig\nfrom langchain.tools import tool\nfrom langgraph.types import interrupt\n\n@tool(\n    run_query_tool.name,\n    description=run_query_tool.description,\n    args_schema=run_query_tool.args_schema\n)\ndef run_query_tool_with_interrupt(config: RunnableConfig, **tool_input):\n    request = {\n        \"action\": run_query_tool.name,\n        \"args\": tool_input,\n        \"description\": \"Please review the tool call\"\n    }\n    response = interrupt([request]) # [!code highlight]\n    # approve the tool call\n    if response[\"type\"] == \"accept\":\n        tool_response = run_query_tool.invoke(tool_input, config)\n    # update tool call args\n    elif response[\"type\"] == \"edit\":\n        tool_input = response[\"args\"][\"args\"]\n        tool_response = run_query_tool.invoke(tool_input, config)\n    # respond to the LLM with user feedback\n    elif response[\"type\"] == \"response\":\n        user_feedback = response[\"args\"]\n        tool_response = user_feedback\n    else:\n        raise ValueError(f\"Unsupported interrupt response type: {response['type']}\")\n\n    return tool_response\n\n# Redefine the tool node to use the interrupt version\nrun_query_node = ToolNode([run_query_tool_with_interrupt], name=\"run_query\") # [!code highlight]\n```\n\n<Note>\n  The above implementation follows the [tool interrupt example](/oss/python/langgraph/interrupts#configuring-interrupts) in the broader [human-in-the-loop](/oss/python/langgraph/interrupts) guide. Refer to that guide for details and alternatives.\n</Note>\n\nLet's now re-assemble our graph. We will replace the programmatic check with human review. Note that we now include a [checkpointer](/oss/python/langgraph/persistence); this is required to pause and resume the run.\n\n```python  theme={null}\nfrom langgraph.checkpoint.memory import InMemorySaver\n\ndef should_continue(state: MessagesState) -> Literal[END, \"run_query\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    if not last_message.tool_calls:\n        return END\n    else:\n        return \"run_query\"\n\nbuilder = StateGraph(MessagesState)\nbuilder.add_node(list_tables)\nbuilder.add_node(call_get_schema)\nbuilder.add_node(get_schema_node, \"get_schema\")\nbuilder.add_node(generate_query)\nbuilder.add_node(run_query_node, \"run_query\")\n\nbuilder.add_edge(START, \"list_tables\")\nbuilder.add_edge(\"list_tables\", \"call_get_schema\")\nbuilder.add_edge(\"call_get_schema\", \"get_schema\")\nbuilder.add_edge(\"get_schema\", \"generate_query\")\nbuilder.add_conditional_edges(\n    \"generate_query\",\n    should_continue,\n)\nbuilder.add_edge(\"run_query\", \"generate_query\")\n\ncheckpointer = InMemorySaver() # [!code highlight]\nagent = builder.compile(checkpointer=checkpointer) # [!code highlight]\n```\n\nWe can invoke the graph as before. This time, execution is interrupted:\n\n```python  theme={null}\nimport json\n\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\n\nquestion = \"Which genre on average has the longest tracks?\"\n\nfor step in agent.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n    config,\n    stream_mode=\"values\",\n):\n    if \"messages\" in step:\n        step[\"messages\"][-1].pretty_print()\n    elif \"__interrupt__\" in step:\n        action = step[\"__interrupt__\"][0]\n        print(\"INTERRUPTED:\")\n        for request in action.value:\n            print(json.dumps(request, indent=2))\n    else:\n        pass\n```\n\n```\n...\n\nINTERRUPTED:\n{\n  \"action\": \"sql_db_query\",\n  \"args\": {\n    \"query\": \"SELECT Genre.Name, AVG(Track.Milliseconds) AS AvgLength FROM Track JOIN Genre ON Track.GenreId = Genre.GenreId GROUP BY Genre.Name ORDER BY AvgLength DESC LIMIT 5;\"\n  },\n  \"description\": \"Please review the tool call\"\n}\n```\n\nWe can accept or edit the tool call using [Command](/oss/python/langgraph/use-graph-api#combine-control-flow-and-state-updates-with-command):\n\n```python  theme={null}\nfrom langgraph.types import Command\n\n\nfor step in agent.stream(\n    Command(resume={\"type\": \"accept\"}),\n    # Command(resume={\"type\": \"edit\", \"args\": {\"query\": \"...\"}}),\n    config,\n    stream_mode=\"values\",\n):\n    if \"messages\" in step:\n        step[\"messages\"][-1].pretty_print()\n    elif \"__interrupt__\" in step:\n        action = step[\"__interrupt__\"][0]\n        print(\"INTERRUPTED:\")\n        for request in action.value:\n            print(json.dumps(request, indent=2))\n    else:\n        pass\n```\n\n```\n================================== Ai Message ==================================\nTool Calls:\n  sql_db_query (call_t4yXkD6shwdTPuelXEmY3sAY)\n Call ID: call_t4yXkD6shwdTPuelXEmY3sAY\n  Args:\n    query: SELECT Genre.Name, AVG(Track.Milliseconds) AS AvgLength FROM Track JOIN Genre ON Track.GenreId = Genre.GenreId GROUP BY Genre.Name ORDER BY AvgLength DESC LIMIT 5;\n================================= Tool Message =================================\nName: sql_db_query\n\n[('Sci Fi & Fantasy', 2911783.0384615385), ('Science Fiction', 2625549.076923077), ('Drama', 2575283.78125), ('TV Shows', 2145041.0215053763), ('Comedy', 1585263.705882353)]\n================================== Ai Message ==================================\n\nThe genre with the longest average track length is \"Sci Fi & Fantasy\" with an average length of about 2,911,783 milliseconds. Other genres with long average track lengths include \"Science Fiction,\" \"Drama,\" \"TV Shows,\" and \"Comedy.\"\n```\n\nRefer to the [human-in-the-loop guide](/oss/python/langgraph/interrupts) for details.", "summary": "Demonstrates implementing human-in-the-loop review for SQL agent queries using LangGraph's interrupt and persistence features to pause execution for approval, editing, or feedback.", "keywords": ["LangGraph", "interrupt", "human-in-the-loop", "SQL query", "persistence layer", "ToolNode", "checkpointer", "Command", "StateGraph", "RunnableConfig"]}