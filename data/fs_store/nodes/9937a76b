{"node_id": "9937a76b", "title": "6. Generate an answer", "path": "agentic-rag > Build a custom RAG agent with LangGraph > 6. Generate an answer", "content": "1. Build `generate_answer` node: if we pass the grader checks, we can generate the final answer based on the original question and the retrieved context:\n\n```python  theme={null}\nGENERATE_PROMPT = (\n    \"You are an assistant for question-answering tasks. \"\n    \"Use the following pieces of retrieved context to answer the question. \"\n    \"If you don't know the answer, just say that you don't know. \"\n    \"Use three sentences maximum and keep the answer concise.\\n\"\n    \"Question: {question} \\n\"\n    \"Context: {context}\"\n)\n\n\ndef generate_answer(state: MessagesState):\n    \"\"\"Generate an answer.\"\"\"\n    question = state[\"messages\"][0].content\n    context = state[\"messages\"][-1].content\n    prompt = GENERATE_PROMPT.format(question=question, context=context)\n    response = response_model.invoke([{\"role\": \"user\", \"content\": prompt}])\n    return {\"messages\": [response]}\n```\n\n2. Try it:\n\n```python  theme={null}\ninput = {\n    \"messages\": convert_to_messages(\n        [\n            {\n                \"role\": \"user\",\n                \"content\": \"What does Lilian Weng say about types of reward hacking?\",\n            },\n            {\n                \"role\": \"assistant\",\n                \"content\": \"\",\n                \"tool_calls\": [\n                    {\n                        \"id\": \"1\",\n                        \"name\": \"retrieve_blog_posts\",\n                        \"args\": {\"query\": \"types of reward hacking\"},\n                    }\n                ],\n            },\n            {\n                \"role\": \"tool\",\n                \"content\": \"reward hacking can be categorized into two types: environment or goal misspecification, and reward tampering\",\n                \"tool_call_id\": \"1\",\n            },\n        ]\n    )\n}\n\nresponse = generate_answer(input)\nresponse[\"messages\"][-1].pretty_print()\n```\n\n**Output:**\n\n```\n================================== Ai Message ==================================\n\nLilian Weng categorizes reward hacking into two types: environment or goal misspecification, and reward tampering. She considers reward hacking as a broad concept that includes both of these categories. Reward hacking occurs when an agent exploits flaws or ambiguities in the reward function to achieve high rewards without performing the intended behaviors.\n```", "summary": "This section details the implementation of a `generate_answer` node in a LangGraph-based RAG agent. It includes the prompt template and function for generating a final answer using retrieved context, and provides a test example with output.", "keywords": ["generate_answer", "GENERATE_PROMPT", "response_model", "MessagesState", "retrieved context", "prompt template", "LangGraph", "RAG agent", "question-answering", "tool_calls"]}