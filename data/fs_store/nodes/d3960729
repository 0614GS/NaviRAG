{"node_id": "d3960729", "title": "Disable streaming for specific chat models", "path": "streaming > Streaming > Disable streaming for specific chat models", "content": "If your application mixes models that support streaming with those that do not, you may need to explicitly disable streaming for\nmodels that do not support it.\n\nSet `streaming=False` when initializing the model.\n\n<Tabs>\n  <Tab title=\"init_chat_model\">\n    ```python  theme={null}\n    from langchain.chat_models import init_chat_model\n\n    model = init_chat_model(\n        \"claude-sonnet-4-5-20250929\",\n        # Set streaming=False to disable streaming for the chat model\n        streaming=False  # [!code highlight]\n    )\n    ```\n  </Tab>\n\n  <Tab title=\"Chat model interface\">\n    ```python  theme={null}\n    from langchain_openai import ChatOpenAI\n\n    # Set streaming=False to disable streaming for the chat model\n    model = ChatOpenAI(model=\"o1-preview\", streaming=False)\n    ```\n  </Tab>\n</Tabs>\n\n<Note>\n  Not all chat model integrations support the `streaming` parameter. If your model doesn't support it, use `disable_streaming=True` instead. This parameter is available on all chat models via the base class.\n</Note>\n\n<a id=\"async\" />", "summary": "How to disable streaming for specific chat models in LangChain by setting streaming=False or disable_streaming=True.", "keywords": ["streaming", "init_chat_model", "ChatOpenAI", "disable_streaming", "streaming=False", "chat model", "LangChain", "async", "RunnableConfig", "LangGraph"]}