{"node_id": "d82be646", "title": "Implementing our email agent nodes", "path": "thinking-in-langgraph > Thinking in LangGraph > Step 4: Build your nodes > Implementing our email agent nodes", "content": "We'll implement each node as a simple function. Remember: nodes take state, do work, and return updates.\n\n<AccordionGroup>\n  <Accordion title=\"Read and classify nodes\" icon=\"brain\">\n    ```python  theme={null}\n    from typing import Literal\n    from langgraph.graph import StateGraph, START, END\n    from langgraph.types import interrupt, Command, RetryPolicy\n    from langchain_openai import ChatOpenAI\n    from langchain.messages import HumanMessage\n\n    llm = ChatOpenAI(model=\"gpt-5-nano\")\n\n    def read_email(state: EmailAgentState) -> dict:\n        \"\"\"Extract and parse email content\"\"\"\n        # In production, this would connect to your email service\n        return {\n            \"messages\": [HumanMessage(content=f\"Processing email: {state['email_content']}\")]\n        }\n\n    def classify_intent(state: EmailAgentState) -> Command[Literal[\"search_documentation\", \"human_review\", \"draft_response\", \"bug_tracking\"]]:\n        \"\"\"Use LLM to classify email intent and urgency, then route accordingly\"\"\"\n\n        # Create structured LLM that returns EmailClassification dict\n        structured_llm = llm.with_structured_output(EmailClassification)\n\n        # Format the prompt on-demand, not stored in state\n        classification_prompt = f\"\"\"\n        Analyze this customer email and classify it:\n\n        Email: {state['email_content']}\n        From: {state['sender_email']}\n\n        Provide classification including intent, urgency, topic, and summary.\n        \"\"\"\n\n        # Get structured response directly as dict\n        classification = structured_llm.invoke(classification_prompt)\n\n        # Determine next node based on classification\n        if classification['intent'] == 'billing' or classification['urgency'] == 'critical':\n            goto = \"human_review\"\n        elif classification['intent'] in ['question', 'feature']:\n            goto = \"search_documentation\"\n        elif classification['intent'] == 'bug':\n            goto = \"bug_tracking\"\n        else:\n            goto = \"draft_response\"\n\n        # Store classification as a single dict in state\n        return Command(\n            update={\"classification\": classification},\n            goto=goto\n        )\n    ```\n  </Accordion>\n\n  <Accordion title=\"Search and tracking nodes\" icon=\"database\">\n    ```python  theme={null}\n    def search_documentation(state: EmailAgentState) -> Command[Literal[\"draft_response\"]]:\n        \"\"\"Search knowledge base for relevant information\"\"\"\n\n        # Build search query from classification\n        classification = state.get('classification', {})\n        query = f\"{classification.get('intent', '')} {classification.get('topic', '')}\"\n\n        try:\n            # Implement your search logic here\n            # Store raw search results, not formatted text\n            search_results = [\n                \"Reset password via Settings > Security > Change Password\",\n                \"Password must be at least 12 characters\",\n                \"Include uppercase, lowercase, numbers, and symbols\"\n            ]\n        except SearchAPIError as e:\n            # For recoverable search errors, store error and continue\n            search_results = [f\"Search temporarily unavailable: {str(e)}\"]\n\n        return Command(\n            update={\"search_results\": search_results},  # Store raw results or error\n            goto=\"draft_response\"\n        )\n\n    def bug_tracking(state: EmailAgentState) -> Command[Literal[\"draft_response\"]]:\n        \"\"\"Create or update bug tracking ticket\"\"\"\n\n        # Create ticket in your bug tracking system\n        ticket_id = \"BUG-12345\"  # Would be created via API\n\n        return Command(\n            update={\n                \"search_results\": [f\"Bug ticket {ticket_id} created\"],\n                \"current_step\": \"bug_tracked\"\n            },\n            goto=\"draft_response\"\n        )\n    ```\n  </Accordion>\n\n  <Accordion title=\"Response nodes\" icon=\"pen-to-square\">\n    ```python  theme={null}\n    def draft_response(state: EmailAgentState) -> Command[Literal[\"human_review\", \"send_reply\"]]:\n        \"\"\"Generate response using context and route based on quality\"\"\"\n\n        classification = state.get('classification', {})\n\n        # Format context from raw state data on-demand\n        context_sections = []\n\n        if state.get('search_results'):\n            # Format search results for the prompt\n            formatted_docs = \"\\n\".join([f\"- {doc}\" for doc in state['search_results']])\n            context_sections.append(f\"Relevant documentation:\\n{formatted_docs}\")\n\n        if state.get('customer_history'):\n            # Format customer data for the prompt\n            context_sections.append(f\"Customer tier: {state['customer_history'].get('tier', 'standard')}\")\n\n        # Build the prompt with formatted context\n        draft_prompt = f\"\"\"\n        Draft a response to this customer email:\n        {state['email_content']}\n\n        Email intent: {classification.get('intent', 'unknown')}\n        Urgency level: {classification.get('urgency', 'medium')}\n\n        {chr(10).join(context_sections)}\n\n        Guidelines:\n        - Be professional and helpful\n        - Address their specific concern\n        - Use the provided documentation when relevant\n        \"\"\"\n\n        response = llm.invoke(draft_prompt)\n\n        # Determine if human review needed based on urgency and intent\n        needs_review = (\n            classification.get('urgency') in ['high', 'critical'] or\n            classification.get('intent') == 'complex'\n        )\n\n        # Route to appropriate next node\n        goto = \"human_review\" if needs_review else \"send_reply\"\n\n        return Command(\n            update={\"draft_response\": response.content},  # Store only the raw response\n            goto=goto\n        )\n\n    def human_review(state: EmailAgentState) -> Command[Literal[\"send_reply\", END]]:\n        \"\"\"Pause for human review using interrupt and route based on decision\"\"\"\n\n        classification = state.get('classification', {})\n\n        # interrupt() must come first - any code before it will re-run on resume\n        human_decision = interrupt({\n            \"email_id\": state.get('email_id',''),\n            \"original_email\": state.get('email_content',''),\n            \"draft_response\": state.get('draft_response',''),\n            \"urgency\": classification.get('urgency'),\n            \"intent\": classification.get('intent'),\n            \"action\": \"Please review and approve/edit this response\"\n        })\n\n        # Now process the human's decision\n        if human_decision.get(\"approved\"):\n            return Command(\n                update={\"draft_response\": human_decision.get(\"edited_response\", state.get('draft_response',''))},\n                goto=\"send_reply\"\n            )\n        else:\n            # Rejection means human will handle directly\n            return Command(update={}, goto=END)\n\n    def send_reply(state: EmailAgentState) -> dict:\n        \"\"\"Send the email response\"\"\"\n        # Integrate with email service\n        print(f\"Sending reply: {state['draft_response'][:100]}...\")\n        return {}\n    ```\n  </Accordion>\n</AccordionGroup>", "summary": "Implements email agent nodes in LangGraph for reading, classifying, searching, drafting, and sending email responses, including human review.", "keywords": ["LangGraph", "EmailAgentState", "Command", "interrupt", "ChatOpenAI", "structured_output", "search_documentation", "bug_tracking", "human_review", "draft_response"]}