{"node_id": "9ecd130e", "title": "2. Create a retriever tool", "path": "agentic-rag > Build a custom RAG agent with LangGraph > 2. Create a retriever tool", "content": "Now that we have our split documents, we can index them into a vector store that we'll use for semantic search.\n\n1. Use an in-memory vector store and OpenAI embeddings:\n\n```python  theme={null}\nfrom langchain_core.vectorstores import InMemoryVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\nvectorstore = InMemoryVectorStore.from_documents(\n    documents=doc_splits, embedding=OpenAIEmbeddings()\n)\nretriever = vectorstore.as_retriever()\n```\n\n2. Create a retriever tool using the `@tool` decorator:\n\n```python  theme={null}\nfrom langchain.tools import tool\n\n@tool\ndef retrieve_blog_posts(query: str) -> str:\n    \"\"\"Search and return information about Lilian Weng blog posts.\"\"\"\n    docs = retriever.invoke(query)\n    return \"\\n\\n\".join([doc.page_content for doc in docs])\n\nretriever_tool = retrieve_blog_posts\n```\n\n3. Test the tool:\n\n```python  theme={null}\nretriever_tool.invoke({\"query\": \"types of reward hacking\"})\n```", "summary": "Demonstrates creating a semantic search retriever tool using an in-memory vector store and OpenAI embeddings, and testing it with a query.", "keywords": ["InMemoryVectorStore", "OpenAIEmbeddings", "retriever", "tool", "semantic search", "vector store", "LangChain", "retrieve_blog_posts", "documents", "query"]}