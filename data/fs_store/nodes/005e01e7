{"node_id": "005e01e7", "title": "Setup", "path": "workflows-agents > Workflows and agents > Setup", "content": "To build a workflow or agent, you can use [any chat model](/oss/python/integrations/chat) that supports structured outputs and tool calling. The following example uses Anthropic:\n\n1. Install dependencies:\n\n```bash  theme={null}\npip install langchain_core langchain-anthropic langgraph\n```\n\n2. Initialize the LLM:\n\n```python  theme={null}\nimport os\nimport getpass\n\nfrom langchain_anthropic import ChatAnthropic\n\ndef _set_env(var: str):\n    if not os.environ.get(var):\n        os.environ[var] = getpass.getpass(f\"{var}: \")\n\n\n_set_env(\"ANTHROPIC_API_KEY\")\n\nllm = ChatAnthropic(model=\"claude-sonnet-4-5-20250929\")\n```", "summary": "Setup instructions for building workflows and agents using a chat model with structured outputs and tool calling, including dependency installation and LLM initialization with Anthropic.", "keywords": ["ChatAnthropic", "structured outputs", "tool calling", "langchain_core", "langchain-anthropic", "langgraph", "ANTHROPIC_API_KEY", "claude-sonnet-4-5-20250929"]}