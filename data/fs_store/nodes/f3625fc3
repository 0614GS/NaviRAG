{"node_id": "f3625fc3", "title": "Run graph nodes in parallel", "path": "use-graph-api > Use the graph API > Create branches > Run graph nodes in parallel", "content": "In this example, we fan out from `Node A` to `B and C` and then fan in to `D`. With our state, [we specify the reducer add operation](/oss/python/langgraph/graph-api#reducers). This will combine or accumulate values for the specific key in the State, rather than simply overwriting the existing value. For lists, this means concatenating the new list with the existing list. See the above section on [state reducers](#process-state-updates-with-reducers) for more detail on updating state with reducers.\n\n```python  theme={null}\nimport operator\nfrom typing import Annotated, Any\nfrom typing_extensions import TypedDict\nfrom langgraph.graph import StateGraph, START, END\n\nclass State(TypedDict):\n    # The operator.add reducer fn makes this append-only\n    aggregate: Annotated[list, operator.add]\n\ndef a(state: State):\n    print(f'Adding \"A\" to {state[\"aggregate\"]}')\n    return {\"aggregate\": [\"A\"]}\n\ndef b(state: State):\n    print(f'Adding \"B\" to {state[\"aggregate\"]}')\n    return {\"aggregate\": [\"B\"]}\n\ndef c(state: State):\n    print(f'Adding \"C\" to {state[\"aggregate\"]}')\n    return {\"aggregate\": [\"C\"]}\n\ndef d(state: State):\n    print(f'Adding \"D\" to {state[\"aggregate\"]}')\n    return {\"aggregate\": [\"D\"]}\n\nbuilder = StateGraph(State)\nbuilder.add_node(a)\nbuilder.add_node(b)\nbuilder.add_node(c)\nbuilder.add_node(d)\nbuilder.add_edge(START, \"a\")\nbuilder.add_edge(\"a\", \"b\")\nbuilder.add_edge(\"a\", \"c\")\nbuilder.add_edge(\"b\", \"d\")\nbuilder.add_edge(\"c\", \"d\")\nbuilder.add_edge(\"d\", END)\ngraph = builder.compile()\n```\n\n```python  theme={null}\nfrom IPython.display import Image, display\n\ndisplay(Image(graph.get_graph().draw_mermaid_png()))\n```\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/graph_api_image_3.png?fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=8359f2e8d9dde03d7cc25f9d755a428d\" alt=\"Parallel execution graph\" data-og-width=\"143\" width=\"143\" data-og-height=\"432\" height=\"432\" data-path=\"oss/images/graph_api_image_3.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/graph_api_image_3.png?w=280&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=75695e23f3e5e7eddb985785376108c4 280w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/graph_api_image_3.png?w=560&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=cf45dc47fcfcf30ef39922a44119d815 560w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/graph_api_image_3.png?w=840&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=92b3e0a7d06b07becf4deab660ff3717 840w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/graph_api_image_3.png?w=1100&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=8c0e296783bde688d32b36e7e8fb669c 1100w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/graph_api_image_3.png?w=1650&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=a4ff2db4eea2ab57343b329f6e21949c 1650w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/graph_api_image_3.png?w=2500&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=99b0250accefffa610c67662ca4be2a2 2500w\" />\n\nWith the reducer, you can see that the values added in each node are accumulated.\n\n```python  theme={null}\ngraph.invoke({\"aggregate\": []}, {\"configurable\": {\"thread_id\": \"foo\"}})\n```\n\n```\nAdding \"A\" to []\nAdding \"B\" to ['A']\nAdding \"C\" to ['A']\nAdding \"D\" to ['A', 'B', 'C']\n```\n\n<Note>\n  In the above example, nodes `\"b\"` and `\"c\"` are executed concurrently in the same [superstep](/oss/python/langgraph/graph-api#graphs). Because they are in the same step, node `\"d\"` executes after both `\"b\"` and `\"c\"` are finished.\n\n  Importantly, updates from a parallel superstep may not be ordered consistently. If you need a consistent, predetermined ordering of updates from a parallel superstep, you should write the outputs to a separate field in the state together with a value with which to order them.\n</Note>\n\n<Accordion title=\"Exception handling?\">\n  LangGraph executes nodes within [supersteps](/oss/python/langgraph/graph-api#graphs), meaning that while parallel branches are executed in parallel, the entire superstep is **transactional**. If any of these branches raises an exception, **none** of the updates are applied to the state (the entire superstep errors).\n\n  Importantly, when using a [checkpointer](/oss/python/langgraph/persistence), results from successful nodes within a superstep are saved, and don't repeat when resumed.\n\n  If you have error-prone (perhaps want to handle flakey API calls), LangGraph provides two ways to address this:\n\n  1. You can write regular python code within your node to catch and handle exceptions.\n  2. You can set a **[retry\\_policy](https://langchain-ai.github.io/langgraph/reference/types/#langgraph.types.RetryPolicy)** to direct the graph to retry nodes that raise certain types of exceptions. Only failing branches are retried, so you needn't worry about performing redundant work.\n\n  Together, these let you perform parallel execution and fully control exception handling.\n</Accordion>\n\n<Tip>\n  **Set max concurrency**\n  You can control the maximum number of concurrent tasks by setting `max_concurrency` in the [configuration](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.config.RunnableConfig.html) when invoking the graph.\n\n  ```python  theme={null}\n  graph.invoke({\"value_1\": \"c\"}, {\"configurable\": {\"max_concurrency\": 10}})\n  ```\n</Tip>", "summary": "Demonstrates parallel execution of graph nodes (B and C) after Node A, using state reducers to accumulate values, and discusses concurrency, exception handling, and max concurrency settings.", "keywords": ["StateGraph", "reducer", "parallel execution", "superstep", "max_concurrency", "exception handling", "checkpointer", "retry_policy", "State", "TypedDict"]}