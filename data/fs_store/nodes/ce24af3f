{"node_id": "ce24af3f", "title": "Streaming", "path": "streaming > Streaming", "content": "LangGraph implements a streaming system to surface real-time updates. Streaming is crucial for enhancing the responsiveness of applications built on LLMs. By displaying output progressively, even before a complete response is ready, streaming significantly improves user experience (UX), particularly when dealing with the latency of LLMs.\n\nWhat's possible with LangGraph streaming:\n\n* <Icon icon=\"share-nodes\" size={16} /> [**Stream graph state**](#stream-graph-state) — get state updates / values with `updates` and `values` modes.\n* <Icon icon=\"square-poll-horizontal\" size={16} /> [**Stream subgraph outputs**](#stream-subgraph-outputs) — include outputs from both the parent graph and any nested subgraphs.\n* <Icon icon=\"square-binary\" size={16} /> [**Stream LLM tokens**](#messages) — capture token streams from anywhere: inside nodes, subgraphs, or tools.\n* <Icon icon=\"table\" size={16} /> [**Stream custom data**](#stream-custom-data) — send custom updates or progress signals directly from tool functions.\n* <Icon icon=\"layer-plus\" size={16} /> [**Use multiple streaming modes**](#stream-multiple-modes) — choose from `values` (full state), `updates` (state deltas), `messages` (LLM tokens + metadata), `custom` (arbitrary user data), or `debug` (detailed traces).", "summary": "LangGraph's streaming system enables real-time updates for LLM applications, covering graph state, subgraph outputs, LLM tokens, custom data, and multiple streaming modes.", "keywords": ["stream", "astream", "stream_mode", "updates", "values", "messages", "custom", "subgraphs", "get_stream_writer", "StateGraph"]}