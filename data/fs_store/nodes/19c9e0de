{"node_id": "19c9e0de", "title": "Creating a simple workflow", "path": "use-functional-api > Use the functional API > Creating a simple workflow", "content": "When defining an `entrypoint`, input is restricted to the first argument of the function. To pass multiple inputs, you can use a dictionary.\n\n```python  theme={null}\n@entrypoint(checkpointer=checkpointer)\ndef my_workflow(inputs: dict) -> int:\n    value = inputs[\"value\"]\n    another_value = inputs[\"another_value\"]\n    ...\n\nmy_workflow.invoke({\"value\": 1, \"another_value\": 2})\n```\n\n<Accordion title=\"Extended example: simple workflow\">\n  ```python  theme={null}\n  import uuid\n  from langgraph.func import entrypoint, task\n  from langgraph.checkpoint.memory import InMemorySaver\n\n  # Task that checks if a number is even\n  @task\n  def is_even(number: int) -> bool:\n      return number % 2 == 0\n\n  # Task that formats a message\n  @task\n  def format_message(is_even: bool) -> str:\n      return \"The number is even.\" if is_even else \"The number is odd.\"\n\n  # Create a checkpointer for persistence\n  checkpointer = InMemorySaver()\n\n  @entrypoint(checkpointer=checkpointer)\n  def workflow(inputs: dict) -> str:\n      \"\"\"Simple workflow to classify a number.\"\"\"\n      even = is_even(inputs[\"number\"]).result()\n      return format_message(even).result()\n\n  # Run the workflow with a unique thread ID\n  config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n  result = workflow.invoke({\"number\": 7}, config=config)\n  print(result)\n  ```\n</Accordion>\n\n<Accordion title=\"Extended example: Compose an essay with an LLM\">\n  This example demonstrates how to use the `@task` and `@entrypoint` decorators\n  syntactically. Given that a checkpointer is provided, the workflow results will\n  be persisted in the checkpointer.\n\n  ```python  theme={null}\n  import uuid\n  from langchain.chat_models import init_chat_model\n  from langgraph.func import entrypoint, task\n  from langgraph.checkpoint.memory import InMemorySaver\n\n  model = init_chat_model('gpt-3.5-turbo')\n\n  # Task: generate essay using an LLM\n  @task\n  def compose_essay(topic: str) -> str:\n      \"\"\"Generate an essay about the given topic.\"\"\"\n      return model.invoke([\n          {\"role\": \"system\", \"content\": \"You are a helpful assistant that writes essays.\"},\n          {\"role\": \"user\", \"content\": f\"Write an essay about {topic}.\"}\n      ]).content\n\n  # Create a checkpointer for persistence\n  checkpointer = InMemorySaver()\n\n  @entrypoint(checkpointer=checkpointer)\n  def workflow(topic: str) -> str:\n      \"\"\"Simple workflow that generates an essay with an LLM.\"\"\"\n      return compose_essay(topic).result()\n\n  # Execute the workflow\n  config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n  result = workflow.invoke(\"the history of flight\", config=config)\n  print(result)\n  ```\n</Accordion>", "summary": "Explains how to create a simple workflow using LangGraph's functional API, including passing multiple inputs via a dictionary and using checkpoints for persistence.", "keywords": ["entrypoint", "task", "checkpointer", "InMemorySaver", "workflow", "invoke", "thread_id", "decorator", "persistence", "functional API"]}