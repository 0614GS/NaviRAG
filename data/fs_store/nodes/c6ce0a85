{"node_id": "c6ce0a85", "title": "Routing", "path": "workflows-agents > Workflows and agents > Routing", "content": "Routing workflows process inputs and then directs them to context-specific tasks. This allows you to define specialized flows for complex tasks. For example, a workflow built to answer product related questions might process the type of question first, and then route the request to specific processes for pricing, refunds, returns, etc.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/dL5Sn6Cmy9pwtY0V/oss/images/routing.png?fit=max&auto=format&n=dL5Sn6Cmy9pwtY0V&q=85&s=272e0e9b681b89cd7d35d5c812c50ee6\" alt=\"routing.png\" data-og-width=\"1214\" width=\"1214\" data-og-height=\"678\" height=\"678\" data-path=\"oss/images/routing.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/dL5Sn6Cmy9pwtY0V/oss/images/routing.png?w=280&fit=max&auto=format&n=dL5Sn6Cmy9pwtY0V&q=85&s=ab85efe91d20c816f9a4e491e92a61f7 280w, https://mintcdn.com/langchain-5e9cc07a/dL5Sn6Cmy9pwtY0V/oss/images/routing.png?w=560&fit=max&auto=format&n=dL5Sn6Cmy9pwtY0V&q=85&s=769e29f9be058a47ee85e0c9228e6e44 560w, https://mintcdn.com/langchain-5e9cc07a/dL5Sn6Cmy9pwtY0V/oss/images/routing.png?w=840&fit=max&auto=format&n=dL5Sn6Cmy9pwtY0V&q=85&s=3711ee40746670731a0ce3e96b7cfeb1 840w, https://mintcdn.com/langchain-5e9cc07a/dL5Sn6Cmy9pwtY0V/oss/images/routing.png?w=1100&fit=max&auto=format&n=dL5Sn6Cmy9pwtY0V&q=85&s=9aaa28410da7643f4a2587f7bfae0f21 1100w, https://mintcdn.com/langchain-5e9cc07a/dL5Sn6Cmy9pwtY0V/oss/images/routing.png?w=1650&fit=max&auto=format&n=dL5Sn6Cmy9pwtY0V&q=85&s=6706326c7fef0511805c684d1e4f7082 1650w, https://mintcdn.com/langchain-5e9cc07a/dL5Sn6Cmy9pwtY0V/oss/images/routing.png?w=2500&fit=max&auto=format&n=dL5Sn6Cmy9pwtY0V&q=85&s=f6d603145ca33791b18c8c8afec0bb4d 2500w\" />\n\n<CodeGroup>\n  ```python Graph API theme={null}\n  from typing_extensions import Literal\n  from langchain.messages import HumanMessage, SystemMessage\n\n\n  # Schema for structured output to use as routing logic\n  class Route(BaseModel):\n      step: Literal[\"poem\", \"story\", \"joke\"] = Field(\n          None, description=\"The next step in the routing process\"\n      )\n\n\n  # Augment the LLM with schema for structured output\n  router = llm.with_structured_output(Route)\n\n\n  # State\n  class State(TypedDict):\n      input: str\n      decision: str\n      output: str\n\n\n  # Nodes\n  def llm_call_1(state: State):\n      \"\"\"Write a story\"\"\"\n\n      result = llm.invoke(state[\"input\"])\n      return {\"output\": result.content}\n\n\n  def llm_call_2(state: State):\n      \"\"\"Write a joke\"\"\"\n\n      result = llm.invoke(state[\"input\"])\n      return {\"output\": result.content}\n\n\n  def llm_call_3(state: State):\n      \"\"\"Write a poem\"\"\"\n\n      result = llm.invoke(state[\"input\"])\n      return {\"output\": result.content}\n\n\n  def llm_call_router(state: State):\n      \"\"\"Route the input to the appropriate node\"\"\"\n\n      # Run the augmented LLM with structured output to serve as routing logic\n      decision = router.invoke(\n          [\n              SystemMessage(\n                  content=\"Route the input to story, joke, or poem based on the user's request.\"\n              ),\n              HumanMessage(content=state[\"input\"]),\n          ]\n      )\n\n      return {\"decision\": decision.step}\n\n\n  # Conditional edge function to route to the appropriate node\n  def route_decision(state: State):\n      # Return the node name you want to visit next\n      if state[\"decision\"] == \"story\":\n          return \"llm_call_1\"\n      elif state[\"decision\"] == \"joke\":\n          return \"llm_call_2\"\n      elif state[\"decision\"] == \"poem\":\n          return \"llm_call_3\"\n\n\n  # Build workflow\n  router_builder = StateGraph(State)\n\n  # Add nodes\n  router_builder.add_node(\"llm_call_1\", llm_call_1)\n  router_builder.add_node(\"llm_call_2\", llm_call_2)\n  router_builder.add_node(\"llm_call_3\", llm_call_3)\n  router_builder.add_node(\"llm_call_router\", llm_call_router)\n\n  # Add edges to connect nodes\n  router_builder.add_edge(START, \"llm_call_router\")\n  router_builder.add_conditional_edges(\n      \"llm_call_router\",\n      route_decision,\n      {  # Name returned by route_decision : Name of next node to visit\n          \"llm_call_1\": \"llm_call_1\",\n          \"llm_call_2\": \"llm_call_2\",\n          \"llm_call_3\": \"llm_call_3\",\n      },\n  )\n  router_builder.add_edge(\"llm_call_1\", END)\n  router_builder.add_edge(\"llm_call_2\", END)\n  router_builder.add_edge(\"llm_call_3\", END)\n\n  # Compile workflow\n  router_workflow = router_builder.compile()\n\n  # Show the workflow\n  display(Image(router_workflow.get_graph().draw_mermaid_png()))\n\n  # Invoke\n  state = router_workflow.invoke({\"input\": \"Write me a joke about cats\"})\n  print(state[\"output\"])\n  ```\n\n  ```python Functional API theme={null}\n  from typing_extensions import Literal\n  from pydantic import BaseModel\n  from langchain.messages import HumanMessage, SystemMessage\n\n\n  # Schema for structured output to use as routing logic\n  class Route(BaseModel):\n      step: Literal[\"poem\", \"story\", \"joke\"] = Field(\n          None, description=\"The next step in the routing process\"\n      )\n\n\n  # Augment the LLM with schema for structured output\n  router = llm.with_structured_output(Route)\n\n\n  @task\n  def llm_call_1(input_: str):\n      \"\"\"Write a story\"\"\"\n      result = llm.invoke(input_)\n      return result.content\n\n\n  @task\n  def llm_call_2(input_: str):\n      \"\"\"Write a joke\"\"\"\n      result = llm.invoke(input_)\n      return result.content\n\n\n  @task\n  def llm_call_3(input_: str):\n      \"\"\"Write a poem\"\"\"\n      result = llm.invoke(input_)\n      return result.content\n\n\n  def llm_call_router(input_: str):\n      \"\"\"Route the input to the appropriate node\"\"\"\n      # Run the augmented LLM with structured output to serve as routing logic\n      decision = router.invoke(\n          [\n              SystemMessage(\n                  content=\"Route the input to story, joke, or poem based on the user's request.\"\n              ),\n              HumanMessage(content=input_),\n          ]\n      )\n      return decision.step\n\n\n  # Create workflow\n  @entrypoint()\n  def router_workflow(input_: str):\n      next_step = llm_call_router(input_)\n      if next_step == \"story\":\n          llm_call = llm_call_1\n      elif next_step == \"joke\":\n          llm_call = llm_call_2\n      elif next_step == \"poem\":\n          llm_call = llm_call_3\n\n      return llm_call(input_).result()\n\n  # Invoke\n  for step in router_workflow.stream(\"Write me a joke about cats\", stream_mode=\"updates\"):\n      print(step)\n      print(\"\\n\")\n  ```\n</CodeGroup>", "summary": "Routing workflows process inputs and direct them to specialized tasks, such as handling product questions by routing to pricing, refunds, or returns processes.", "keywords": ["Routing", "StateGraph", "with_structured_output", "conditional_edges", "TypedDict", "BaseModel", "Literal", "LLM", "workflow", "entrypoint"]}