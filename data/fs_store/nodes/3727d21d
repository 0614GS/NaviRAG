{"node_id": "3727d21d", "title": "Non-deterministic control flow", "path": "functional-api > Functional API overview > Common Pitfalls > Non-deterministic control flow", "content": "Operations that might give different results each time (like getting current time or random numbers) should be encapsulated in tasks to ensure that on resume, the same result is returned.\n\n* In a task: Get random number (5) → interrupt → resume → (returns 5 again) → ...\n* Not in a task: Get random number (5) → interrupt → resume → get new random number (7) → ...\n\nThis is especially important when using **human-in-the-loop** workflows with multiple interrupts calls. LangGraph keeps a list of resume values for each task/entrypoint. When an interrupt is encountered, it's matched with the corresponding resume value. This matching is strictly **index-based**, so the order of the resume values should match the order of the interrupts.\n\nIf order of execution is not maintained when resuming, one [`interrupt`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.interrupt) call may be matched with the wrong `resume` value, leading to incorrect results.\n\nPlease read the section on [determinism](#determinism) for more details.\n\n<Tabs>\n  <Tab title=\"Incorrect\">\n    In this example, the workflow uses the current time to determine which task to execute. This is non-deterministic because the result of the workflow depends on the time at which it is executed.\n\n    ```python  theme={null}\n    from langgraph.func import entrypoint\n\n    @entrypoint(checkpointer=checkpointer)\n    def my_workflow(inputs: dict) -> int:\n        t0 = inputs[\"t0\"]\n        t1 = time.time()  # [!code highlight]\n\n        delta_t = t1 - t0\n\n        if delta_t > 1:\n            result = slow_task(1).result()\n            value = interrupt(\"question\")\n        else:\n            result = slow_task(2).result()\n            value = interrupt(\"question\")\n\n        return {\n            \"result\": result,\n            \"value\": value\n        }\n    ```\n  </Tab>\n\n  <Tab title=\"Correct\">\n    In this example, the workflow uses the input `t0` to determine which task to execute. This is deterministic because the result of the workflow depends only on the input.\n\n    ```python  theme={null}\n    import time\n\n    from langgraph.func import task\n\n    @task  # [!code highlight]\n    def get_time() -> float:  # [!code highlight]\n        return time.time()\n\n    @entrypoint(checkpointer=checkpointer)\n    def my_workflow(inputs: dict) -> int:\n        t0 = inputs[\"t0\"]\n        t1 = get_time().result()  # [!code highlight]\n\n        delta_t = t1 - t0\n\n        if delta_t > 1:\n            result = slow_task(1).result()\n            value = interrupt(\"question\")\n        else:\n            result = slow_task(2).result()\n            value = interrupt(\"question\")\n\n        return {\n            \"result\": result,\n            \"value\": value\n        }\n    ```\n  </Tab>\n</Tabs>\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/langgraph/functional-api.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\n> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.langchain.com/llms.txt", "summary": "Explains the importance of encapsulating non-deterministic operations (e.g., random numbers, time) within tasks in LangGraph to ensure deterministic resumption after interrupts, using code examples to illustrate correct and incorrect patterns.", "keywords": ["LangGraph", "non-deterministic", "interrupt", "resume", "task", "determinism", "human-in-the-loop", "entrypoint", "checkpointer", "control flow"]}