{"node_id": "38e80bf6", "title": "1. Preprocess documents", "path": "agentic-rag > Build a custom RAG agent with LangGraph > 1. Preprocess documents", "content": "1. Fetch documents to use in our RAG system. We will use three of the most recent pages from [Lilian Weng's excellent blog](https://lilianweng.github.io/). We'll start by fetching the content of the pages using `WebBaseLoader` utility:\n\n```python  theme={null}\nfrom langchain_community.document_loaders import WebBaseLoader\n\nurls = [\n    \"https://lilianweng.github.io/posts/2024-11-28-reward-hacking/\",\n    \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n    \"https://lilianweng.github.io/posts/2024-04-12-diffusion-video/\",\n]\n\ndocs = [WebBaseLoader(url).load() for url in urls]\n```\n\n```python  theme={null}\ndocs[0][0].page_content.strip()[:1000]\n```\n\n2. Split the fetched documents into smaller chunks for indexing into our vectorstore:\n\n```python  theme={null}\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\n\ndocs_list = [item for sublist in docs for item in sublist]\n\ntext_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n    chunk_size=100, chunk_overlap=50\n)\ndoc_splits = text_splitter.split_documents(docs_list)\n```\n\n```python  theme={null}\ndoc_splits[0].page_content.strip()\n```", "summary": "Demonstrates fetching blog posts using WebBaseLoader and splitting them into chunks with RecursiveCharacterTextSplitter for RAG preprocessing.", "keywords": ["WebBaseLoader", "RecursiveCharacterTextSplitter", "chunk_size", "chunk_overlap", "document_splits", "RAG", "LangChain", "vectorstore", "tiktoken_encoder", "page_content"]}