{"node_id": "f1f5bc17", "title": "Chatbot example", "path": "use-functional-api > Use the functional API > Short-term memory > Chatbot example", "content": "An example of a simple chatbot using the functional API and the [`InMemorySaver`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.memory.InMemorySaver) checkpointer.\n\nThe bot is able to remember the previous conversation and continue from where it left off.\n\n```python  theme={null}\nfrom langchain.messages import BaseMessage\nfrom langgraph.graph import add_messages\nfrom langgraph.func import entrypoint, task\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langchain_anthropic import ChatAnthropic\n\nmodel = ChatAnthropic(model=\"claude-sonnet-4-5-20250929\")\n\n@task\ndef call_model(messages: list[BaseMessage]):\n    response = model.invoke(messages)\n    return response\n\ncheckpointer = InMemorySaver()\n\n@entrypoint(checkpointer=checkpointer)\ndef workflow(inputs: list[BaseMessage], *, previous: list[BaseMessage]):\n    if previous:\n        inputs = add_messages(previous, inputs)\n\n    response = call_model(inputs).result()\n    return entrypoint.final(value=response, save=add_messages(inputs, response))\n\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\ninput_message = {\"role\": \"user\", \"content\": \"hi! I'm bob\"}\nfor chunk in workflow.stream([input_message], config, stream_mode=\"values\"):\n    chunk.pretty_print()\n\ninput_message = {\"role\": \"user\", \"content\": \"what's my name?\"}\nfor chunk in workflow.stream([input_message], config, stream_mode=\"values\"):\n    chunk.pretty_print()\n```", "summary": "A simple chatbot example using LangGraph's functional API and InMemorySaver for conversation memory, demonstrating multi-turn dialogue.", "keywords": ["LangGraph", "functional API", "InMemorySaver", "ChatAnthropic", "checkpointer", "workflow", "entrypoint", "task", "BaseMessage", "add_messages"]}