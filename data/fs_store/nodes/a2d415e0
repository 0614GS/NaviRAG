{"node_id": "a2d415e0", "title": "Advanced considerations", "path": "thinking-in-langgraph > Thinking in LangGraph > Summary and next steps > Advanced considerations", "content": "<Accordion title=\"Node granularity trade-offs\" icon=\"sliders\">\n  <Info>\n    This section explores the trade-offs in node granularity design. Most applications can skip this and use the patterns shown above.\n  </Info>\n\n  You might wonder: why not combine `Read Email` and `Classify Intent` into one node?\n\n  Or why separate Doc Search from Draft Reply?\n\n  The answer involves trade-offs between resilience and observability.\n\n  **The resilience consideration:** LangGraph's [durable execution](/oss/python/langgraph/durable-execution) creates checkpoints at node boundaries. When a workflow resumes after an interruption or failure, it starts from the beginning of the node where execution stopped. Smaller nodes mean more frequent checkpoints, which means less work to repeat if something goes wrong. If you combine multiple operations into one large node, a failure near the end means re-executing everything from the start of that node.\n\n  Why we chose this breakdown for the email agent:\n\n  * **Isolation of external services:** Doc Search and Bug Track are separate nodes because they call external APIs. If the search service is slow or fails, we want to isolate that from the LLM calls. We can add retry policies to these specific nodes without affecting others.\n\n  * **Intermediate visibility:** Having `Classify Intent` as its own node lets us inspect what the LLM decided before taking action. This is valuable for debugging and monitoring—you can see exactly when and why the agent routes to human review.\n\n  * **Different failure modes:** LLM calls, database lookups, and email sending have different retry strategies. Separate nodes let you configure these independently.\n\n  * **Reusability and testing:** Smaller nodes are easier to test in isolation and reuse in other workflows.\n\n  A different valid approach: You could combine `Read Email` and `Classify Intent` into a single node. You'd lose the ability to inspect the raw email before classification and would repeat both operations on any failure in that node. For most applications, the observability and debugging benefits of separate nodes are worth the trade-off.\n\n  Application-level concerns: The caching discussion in Step 2 (whether to cache search results) is an application-level decision, not a LangGraph framework feature. You implement caching within your node functions based on your specific requirements—LangGraph doesn't prescribe this.\n\n  Performance considerations: More nodes doesn't mean slower execution. LangGraph writes checkpoints in the background by default ([async durability mode](/oss/python/langgraph/durable-execution#durability-modes)), so your graph continues running without waiting for checkpoints to complete. This means you get frequent checkpoints with minimal performance impact. You can adjust this behavior if needed—use `\"exit\"` mode to checkpoint only at completion, or `\"sync\"` mode to block execution until each checkpoint is written.\n</Accordion>", "summary": "Discusses trade-offs in node granularity design in LangGraph, focusing on resilience, observability, and performance considerations for workflow nodes.", "keywords": ["LangGraph", "node granularity", "durable execution", "checkpoints", "resilience", "observability", "retry policies", "external services", "async durability mode", "workflow"]}