{"node_id": "e61fcede", "title": "3. Generate query", "path": "agentic-rag > Build a custom RAG agent with LangGraph > 3. Generate query", "content": "Now we will start building components ([nodes](/oss/python/langgraph/graph-api#nodes) and [edges](/oss/python/langgraph/graph-api#edges)) for our agentic RAG graph.\n\nNote that the components will operate on the [`MessagesState`](/oss/python/langgraph/graph-api#messagesstate) â€” graph state that contains a `messages` key with a list of [chat messages](https://python.langchain.com/docs/concepts/messages/).\n\n1. Build a `generate_query_or_respond` node. It will call an LLM to generate a response based on the current graph state (list of messages). Given the input messages, it will decide to retrieve using the retriever tool, or respond directly to the user. Note that we're giving the chat model access to the `retriever_tool` we created earlier via `.bind_tools`:\n\n```python  theme={null}\nfrom langgraph.graph import MessagesState\nfrom langchain.chat_models import init_chat_model\n\nresponse_model = init_chat_model(\"gpt-4o\", temperature=0)\n\n\ndef generate_query_or_respond(state: MessagesState):\n    \"\"\"Call the model to generate a response based on the current state. Given\n    the question, it will decide to retrieve using the retriever tool, or simply respond to the user.\n    \"\"\"\n    response = (\n        response_model\n        .bind_tools([retriever_tool]).invoke(state[\"messages\"])  # [!code highlight]\n    )\n    return {\"messages\": [response]}\n```\n\n2. Try it on a random input:\n\n```python  theme={null}\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"hello!\"}]}\ngenerate_query_or_respond(input)[\"messages\"][-1].pretty_print()\n```\n\n**Output:**\n\n```\n================================== Ai Message ==================================\n\nHello! How can I help you today?\n```\n\n3. Ask a question that requires semantic search:\n\n```python  theme={null}\ninput = {\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"What does Lilian Weng say about types of reward hacking?\",\n        }\n    ]\n}\ngenerate_query_or_respond(input)[\"messages\"][-1].pretty_print()\n```\n\n**Output:**\n\n```\n================================== Ai Message ==================================\nTool Calls:\nretrieve_blog_posts (call_tYQxgfIlnQUDMdtAhdbXNwIM)\nCall ID: call_tYQxgfIlnQUDMdtAhdbXNwIM\nArgs:\n    query: types of reward hacking\n```", "summary": "Builds a LangGraph node that uses an LLM to decide between retrieving information or responding directly based on input messages.", "keywords": ["LangGraph", "MessagesState", "generate_query_or_respond", "bind_tools", "retriever_tool", "LLM", "node", "agentic RAG", "semantic search"]}