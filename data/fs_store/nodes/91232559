{"node_id": "91232559", "title": "Use in production", "path": "add-memory > Memory > Add long-term memory > Use in production", "content": "In production, use a store backed by a database:\n\n```python  theme={null}\nfrom langgraph.store.postgres import PostgresStore\n\nDB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\nwith PostgresStore.from_conn_string(DB_URI) as store:  # [!code highlight]\n    builder = StateGraph(...)\n    graph = builder.compile(store=store)  # [!code highlight]\n```\n\n<Accordion title=\"Example: using Postgres store\">\n  ```\n  pip install -U \"psycopg[binary,pool]\" langgraph langgraph-checkpoint-postgres\n  ```\n\n  <Tip>\n    You need to call `store.setup()` the first time you're using Postgres store\n  </Tip>\n\n  <Tabs>\n    <Tab title=\"Sync\">\n      ```python  theme={null}\n      from langchain_core.runnables import RunnableConfig\n      from langchain.chat_models import init_chat_model\n      from langgraph.graph import StateGraph, MessagesState, START\n      from langgraph.checkpoint.postgres import PostgresSaver\n      from langgraph.store.postgres import PostgresStore  # [!code highlight]\n      from langgraph.store.base import BaseStore\n\n      model = init_chat_model(model=\"claude-haiku-4-5-20251001\")\n\n      DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n\n      with (\n          PostgresStore.from_conn_string(DB_URI) as store,  # [!code highlight]\n          PostgresSaver.from_conn_string(DB_URI) as checkpointer,\n      ):\n          # store.setup()\n          # checkpointer.setup()\n\n          def call_model(\n              state: MessagesState,\n              config: RunnableConfig,\n              *,\n              store: BaseStore,  # [!code highlight]\n          ):\n              user_id = config[\"configurable\"][\"user_id\"]\n              namespace = (\"memories\", user_id)\n              memories = store.search(namespace, query=str(state[\"messages\"][-1].content))  # [!code highlight]\n              info = \"\\n\".join([d.value[\"data\"] for d in memories])\n              system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n\n              # Store new memories if the user asks the model to remember\n              last_message = state[\"messages\"][-1]\n              if \"remember\" in last_message.content.lower():\n                  memory = \"User name is Bob\"\n                  store.put(namespace, str(uuid.uuid4()), {\"data\": memory})  # [!code highlight]\n\n              response = model.invoke(\n                  [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n              )\n              return {\"messages\": response}\n\n          builder = StateGraph(MessagesState)\n          builder.add_node(call_model)\n          builder.add_edge(START, \"call_model\")\n\n          graph = builder.compile(\n              checkpointer=checkpointer,\n              store=store,  # [!code highlight]\n          )\n\n          config = {\n              \"configurable\": {\n                  \"thread_id\": \"1\",  # [!code highlight]\n                  \"user_id\": \"1\",  # [!code highlight]\n              }\n          }\n          for chunk in graph.stream(\n              {\"messages\": [{\"role\": \"user\", \"content\": \"Hi! Remember: my name is Bob\"}]},\n              config,  # [!code highlight]\n              stream_mode=\"values\",\n          ):\n              chunk[\"messages\"][-1].pretty_print()\n\n          config = {\n              \"configurable\": {\n                  \"thread_id\": \"2\",  # [!code highlight]\n                  \"user_id\": \"1\",\n              }\n          }\n\n          for chunk in graph.stream(\n              {\"messages\": [{\"role\": \"user\", \"content\": \"what is my name?\"}]},\n              config,  # [!code highlight]\n              stream_mode=\"values\",\n          ):\n              chunk[\"messages\"][-1].pretty_print()\n      ```\n    </Tab>\n\n    <Tab title=\"Async\">\n      ```python  theme={null}\n      from langchain_core.runnables import RunnableConfig\n      from langchain.chat_models import init_chat_model\n      from langgraph.graph import StateGraph, MessagesState, START\n      from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver\n      from langgraph.store.postgres.aio import AsyncPostgresStore  # [!code highlight]\n      from langgraph.store.base import BaseStore\n\n      model = init_chat_model(model=\"claude-haiku-4-5-20251001\")\n\n      DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n\n      async with (\n          AsyncPostgresStore.from_conn_string(DB_URI) as store,  # [!code highlight]\n          AsyncPostgresSaver.from_conn_string(DB_URI) as checkpointer,\n      ):\n          # await store.setup()\n          # await checkpointer.setup()\n\n          async def call_model(\n              state: MessagesState,\n              config: RunnableConfig,\n              *,\n              store: BaseStore,  # [!code highlight]\n          ):\n              user_id = config[\"configurable\"][\"user_id\"]\n              namespace = (\"memories\", user_id)\n              memories = await store.asearch(namespace, query=str(state[\"messages\"][-1].content))  # [!code highlight]\n              info = \"\\n\".join([d.value[\"data\"] for d in memories])\n              system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n\n              # Store new memories if the user asks the model to remember\n              last_message = state[\"messages\"][-1]\n              if \"remember\" in last_message.content.lower():\n                  memory = \"User name is Bob\"\n                  await store.aput(namespace, str(uuid.uuid4()), {\"data\": memory})  # [!code highlight]\n\n              response = await model.ainvoke(\n                  [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n              )\n              return {\"messages\": response}\n\n          builder = StateGraph(MessagesState)\n          builder.add_node(call_model)\n          builder.add_edge(START, \"call_model\")\n\n          graph = builder.compile(\n              checkpointer=checkpointer,\n              store=store,  # [!code highlight]\n          )\n\n          config = {\n              \"configurable\": {\n                  \"thread_id\": \"1\",  # [!code highlight]\n                  \"user_id\": \"1\",  # [!code highlight]\n              }\n          }\n          async for chunk in graph.astream(\n              {\"messages\": [{\"role\": \"user\", \"content\": \"Hi! Remember: my name is Bob\"}]},\n              config,  # [!code highlight]\n              stream_mode=\"values\",\n          ):\n              chunk[\"messages\"][-1].pretty_print()\n\n          config = {\n              \"configurable\": {\n                  \"thread_id\": \"2\",  # [!code highlight]\n                  \"user_id\": \"1\",\n              }\n          }\n\n          async for chunk in graph.astream(\n              {\"messages\": [{\"role\": \"user\", \"content\": \"what is my name?\"}]},\n              config,  # [!code highlight]\n              stream_mode=\"values\",\n          ):\n              chunk[\"messages\"][-1].pretty_print()\n      ```\n    </Tab>\n  </Tabs>\n</Accordion>\n\n<Accordion title=\"Example: using Redis store\">\n  ```\n  pip install -U langgraph langgraph-checkpoint-redis\n  ```\n\n  <Tip>\n    You need to call `store.setup()` the first time you're using [Redis store](https://pypi.org/project/langgraph-checkpoint-redis/).\n  </Tip>\n\n  <Tabs>\n    <Tab title=\"Sync\">\n      ```python  theme={null}\n      from langchain_core.runnables import RunnableConfig\n      from langchain.chat_models import init_chat_model\n      from langgraph.graph import StateGraph, MessagesState, START\n      from langgraph.checkpoint.redis import RedisSaver\n      from langgraph.store.redis import RedisStore  # [!code highlight]\n      from langgraph.store.base import BaseStore\n\n      model = init_chat_model(model=\"claude-haiku-4-5-20251001\")\n\n      DB_URI = \"redis://localhost:6379\"\n\n      with (\n          RedisStore.from_conn_string(DB_URI) as store,  # [!code highlight]\n          RedisSaver.from_conn_string(DB_URI) as checkpointer,\n      ):\n          store.setup()\n          checkpointer.setup()\n\n          def call_model(\n              state: MessagesState,\n              config: RunnableConfig,\n              *,\n              store: BaseStore,  # [!code highlight]\n          ):\n              user_id = config[\"configurable\"][\"user_id\"]\n              namespace = (\"memories\", user_id)\n              memories = store.search(namespace, query=str(state[\"messages\"][-1].content))  # [!code highlight]\n              info = \"\\n\".join([d.value[\"data\"] for d in memories])\n              system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n\n              # Store new memories if the user asks the model to remember\n              last_message = state[\"messages\"][-1]\n              if \"remember\" in last_message.content.lower():\n                  memory = \"User name is Bob\"\n                  store.put(namespace, str(uuid.uuid4()), {\"data\": memory})  # [!code highlight]\n\n              response = model.invoke(\n                  [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n              )\n              return {\"messages\": response}\n\n          builder = StateGraph(MessagesState)\n          builder.add_node(call_model)\n          builder.add_edge(START, \"call_model\")\n\n          graph = builder.compile(\n              checkpointer=checkpointer,\n              store=store,  # [!code highlight]\n          )\n\n          config = {\n              \"configurable\": {\n                  \"thread_id\": \"1\",  # [!code highlight]\n                  \"user_id\": \"1\",  # [!code highlight]\n              }\n          }\n          for chunk in graph.stream(\n              {\"messages\": [{\"role\": \"user\", \"content\": \"Hi! Remember: my name is Bob\"}]},\n              config,  # [!code highlight]\n              stream_mode=\"values\",\n          ):\n              chunk[\"messages\"][-1].pretty_print()\n\n          config = {\n              \"configurable\": {\n                  \"thread_id\": \"2\",  # [!code highlight]\n                  \"user_id\": \"1\",\n              }\n          }\n\n          for chunk in graph.stream(\n              {\"messages\": [{\"role\": \"user\", \"content\": \"what is my name?\"}]},\n              config,  # [!code highlight]\n              stream_mode=\"values\",\n          ):\n              chunk[\"messages\"][-1].pretty_print()\n      ```\n    </Tab>\n\n    <Tab title=\"Async\">\n      ```python  theme={null}\n      from langchain_core.runnables import RunnableConfig\n      from langchain.chat_models import init_chat_model\n      from langgraph.graph import StateGraph, MessagesState, START\n      from langgraph.checkpoint.redis.aio import AsyncRedisSaver\n      from langgraph.store.redis.aio import AsyncRedisStore  # [!code highlight]\n      from langgraph.store.base import BaseStore\n\n      model = init_chat_model(model=\"claude-haiku-4-5-20251001\")\n\n      DB_URI = \"redis://localhost:6379\"\n\n      async with (\n          AsyncRedisStore.from_conn_string(DB_URI) as store,  # [!code highlight]\n          AsyncRedisSaver.from_conn_string(DB_URI) as checkpointer,\n      ):\n          # await store.setup()\n          # await checkpointer.asetup()\n\n          async def call_model(\n              state: MessagesState,\n              config: RunnableConfig,\n              *,\n              store: BaseStore,  # [!code highlight]\n          ):\n              user_id = config[\"configurable\"][\"user_id\"]\n              namespace = (\"memories\", user_id)\n              memories = await store.asearch(namespace, query=str(state[\"messages\"][-1].content))  # [!code highlight]\n              info = \"\\n\".join([d.value[\"data\"] for d in memories])\n              system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n\n              # Store new memories if the user asks the model to remember\n              last_message = state[\"messages\"][-1]\n              if \"remember\" in last_message.content.lower():\n                  memory = \"User name is Bob\"\n                  await store.aput(namespace, str(uuid.uuid4()), {\"data\": memory})  # [!code highlight]\n\n              response = await model.ainvoke(\n                  [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n              )\n              return {\"messages\": response}\n\n          builder = StateGraph(MessagesState)\n          builder.add_node(call_model)\n          builder.add_edge(START, \"call_model\")\n\n          graph = builder.compile(\n              checkpointer=checkpointer,\n              store=store,  # [!code highlight]\n          )\n\n          config = {\n              \"configurable\": {\n                  \"thread_id\": \"1\",  # [!code highlight]\n                  \"user_id\": \"1\",  # [!code highlight]\n              }\n          }\n          async for chunk in graph.astream(\n              {\"messages\": [{\"role\": \"user\", \"content\": \"Hi! Remember: my name is Bob\"}]},\n              config,  # [!code highlight]\n              stream_mode=\"values\",\n          ):\n              chunk[\"messages\"][-1].pretty_print()\n\n          config = {\n              \"configurable\": {\n                  \"thread_id\": \"2\",  # [!code highlight]\n                  \"user_id\": \"1\",\n              }\n          }\n\n          async for chunk in graph.astream(\n              {\"messages\": [{\"role\": \"user\", \"content\": \"what is my name?\"}]},\n              config,  # [!code highlight]\n              stream_mode=\"values\",\n          ):\n              chunk[\"messages\"][-1].pretty_print()\n      ```\n    </Tab>\n  </Tabs>\n</Accordion>", "summary": "Demonstrates how to integrate persistent storage (Postgres and Redis) into a LangGraph application for production use, including setup, configuration, and usage examples for both sync and async operations.", "keywords": ["PostgresStore", "RedisStore", "StateGraph", "checkpointer", "namespace", "search", "put", "configurable", "thread_id", "user_id"]}