{"node_id": "0c98775a", "title": "Orchestrator-worker", "path": "workflows-agents > Workflows and agents > Orchestrator-worker", "content": "In an orchestrator-worker configuration, the orchestrator:\n\n* Breaks down tasks into subtasks\n* Delegates subtasks to workers\n* Synthesizes worker outputs into a final result\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/ybiAaBfoBvFquMDz/oss/images/worker.png?fit=max&auto=format&n=ybiAaBfoBvFquMDz&q=85&s=2e423c67cd4f12e049cea9c169ff0676\" alt=\"worker.png\" data-og-width=\"1486\" width=\"1486\" data-og-height=\"548\" height=\"548\" data-path=\"oss/images/worker.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/ybiAaBfoBvFquMDz/oss/images/worker.png?w=280&fit=max&auto=format&n=ybiAaBfoBvFquMDz&q=85&s=037222991ea08f889306be035c4730b6 280w, https://mintcdn.com/langchain-5e9cc07a/ybiAaBfoBvFquMDz/oss/images/worker.png?w=560&fit=max&auto=format&n=ybiAaBfoBvFquMDz&q=85&s=081f3ff05cc1fe50770c864d74084b5b 560w, https://mintcdn.com/langchain-5e9cc07a/ybiAaBfoBvFquMDz/oss/images/worker.png?w=840&fit=max&auto=format&n=ybiAaBfoBvFquMDz&q=85&s=0ef6c1b9ceb5159030aa34d0f05f1ada 840w, https://mintcdn.com/langchain-5e9cc07a/ybiAaBfoBvFquMDz/oss/images/worker.png?w=1100&fit=max&auto=format&n=ybiAaBfoBvFquMDz&q=85&s=92ec7353a89ae96e221a5a8f65c88adf 1100w, https://mintcdn.com/langchain-5e9cc07a/ybiAaBfoBvFquMDz/oss/images/worker.png?w=1650&fit=max&auto=format&n=ybiAaBfoBvFquMDz&q=85&s=71b201dd99fa234ebfb918915aac3295 1650w, https://mintcdn.com/langchain-5e9cc07a/ybiAaBfoBvFquMDz/oss/images/worker.png?w=2500&fit=max&auto=format&n=ybiAaBfoBvFquMDz&q=85&s=4f7b6e2064db575027932394a3658fbd 2500w\" />\n\nOrchestrator-worker workflows provide more flexibility and are often used when subtasks cannot be predefined the way they can with [parallelization](#parallelization). This is common with workflows that write code or need to update content across multiple files. For example, a workflow that needs to update installation instructions for multiple Python libraries across an unknown number of documents might use this pattern.\n\n<CodeGroup>\n  ```python Graph API theme={null}\n  from typing import Annotated, List\n  import operator\n\n\n  # Schema for structured output to use in planning\n  class Section(BaseModel):\n      name: str = Field(\n          description=\"Name for this section of the report.\",\n      )\n      description: str = Field(\n          description=\"Brief overview of the main topics and concepts to be covered in this section.\",\n      )\n\n\n  class Sections(BaseModel):\n      sections: List[Section] = Field(\n          description=\"Sections of the report.\",\n      )\n\n\n  # Augment the LLM with schema for structured output\n  planner = llm.with_structured_output(Sections)\n  ```\n\n  ```python Functional API theme={null}\n  from typing import List\n\n\n  # Schema for structured output to use in planning\n  class Section(BaseModel):\n      name: str = Field(\n          description=\"Name for this section of the report.\",\n      )\n      description: str = Field(\n          description=\"Brief overview of the main topics and concepts to be covered in this section.\",\n      )\n\n\n  class Sections(BaseModel):\n      sections: List[Section] = Field(\n          description=\"Sections of the report.\",\n      )\n\n\n  # Augment the LLM with schema for structured output\n  planner = llm.with_structured_output(Sections)\n\n\n  @task\n  def orchestrator(topic: str):\n      \"\"\"Orchestrator that generates a plan for the report\"\"\"\n      # Generate queries\n      report_sections = planner.invoke(\n          [\n              SystemMessage(content=\"Generate a plan for the report.\"),\n              HumanMessage(content=f\"Here is the report topic: {topic}\"),\n          ]\n      )\n\n      return report_sections.sections\n\n\n  @task\n  def llm_call(section: Section):\n      \"\"\"Worker writes a section of the report\"\"\"\n\n      # Generate section\n      result = llm.invoke(\n          [\n              SystemMessage(content=\"Write a report section.\"),\n              HumanMessage(\n                  content=f\"Here is the section name: {section.name} and description: {section.description}\"\n              ),\n          ]\n      )\n\n      # Write the updated section to completed sections\n      return result.content\n\n\n  @task\n  def synthesizer(completed_sections: list[str]):\n      \"\"\"Synthesize full report from sections\"\"\"\n      final_report = \"\\n\\n---\\n\\n\".join(completed_sections)\n      return final_report\n\n\n  @entrypoint()\n  def orchestrator_worker(topic: str):\n      sections = orchestrator(topic).result()\n      section_futures = [llm_call(section) for section in sections]\n      final_report = synthesizer(\n          [section_fut.result() for section_fut in section_futures]\n      ).result()\n      return final_report\n\n  # Invoke\n  report = orchestrator_worker.invoke(\"Create a report on LLM scaling laws\")\n  from IPython.display import Markdown\n  Markdown(report)\n  ```\n</CodeGroup>", "summary": "Describes the orchestrator-worker pattern where an orchestrator decomposes tasks, delegates subtasks to workers, and synthesizes results, with examples for dynamic workflows like code generation.", "keywords": ["orchestrator", "worker", "subtasks", "parallelization", "LangGraph", "Send API", "StateGraph", "TypedDict", "llm_call", "synthesizer"]}