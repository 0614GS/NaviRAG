{"node_id": "e99c7a41", "title": "7. Assemble the graph", "path": "agentic-rag > Build a custom RAG agent with LangGraph > 7. Assemble the graph", "content": "Now we'll assemble all the nodes and edges into a complete graph:\n\n* Start with a `generate_query_or_respond` and determine if we need to call `retriever_tool`\n* Route to next step using `tools_condition`:\n  * If `generate_query_or_respond` returned `tool_calls`, call `retriever_tool` to retrieve context\n  * Otherwise, respond directly to the user\n* Grade retrieved document content for relevance to the question (`grade_documents`) and route to next step:\n  * If not relevant, rewrite the question using `rewrite_question` and then call `generate_query_or_respond` again\n  * If relevant, proceed to `generate_answer` and generate final response using the [`ToolMessage`](https://reference.langchain.com/python/langchain/messages/#langchain.messages.ToolMessage) with the retrieved document context\n\n```python  theme={null}\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.prebuilt import ToolNode, tools_condition\n\nworkflow = StateGraph(MessagesState)\n\n# Define the nodes we will cycle between\nworkflow.add_node(generate_query_or_respond)\nworkflow.add_node(\"retrieve\", ToolNode([retriever_tool]))\nworkflow.add_node(rewrite_question)\nworkflow.add_node(generate_answer)\n\nworkflow.add_edge(START, \"generate_query_or_respond\")\n\n# Decide whether to retrieve\nworkflow.add_conditional_edges(\n    \"generate_query_or_respond\",\n    # Assess LLM decision (call `retriever_tool` tool or respond to the user)\n    tools_condition,\n    {\n        # Translate the condition outputs to nodes in our graph\n        \"tools\": \"retrieve\",\n        END: END,\n    },\n)\n\n# Edges taken after the `action` node is called.\nworkflow.add_conditional_edges(\n    \"retrieve\",\n    # Assess agent decision\n    grade_documents,\n)\nworkflow.add_edge(\"generate_answer\", END)\nworkflow.add_edge(\"rewrite_question\", \"generate_query_or_respond\")\n\n# Compile\ngraph = workflow.compile()\n```\n\nVisualize the graph:\n\n```python  theme={null}\nfrom IPython.display import Image, display\n\ndisplay(Image(graph.get_graph().draw_mermaid_png()))\n```\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agentic-rag-output.png?fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=ddedbd57514888e614ece260092201df\" alt=\"SQL agent graph\" style={{ height: \"800px\" }} data-og-width=\"1245\" width=\"1245\" data-og-height=\"1395\" height=\"1395\" data-path=\"oss/images/agentic-rag-output.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agentic-rag-output.png?w=280&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=e8ade9698046fa97bd4600ffc0ee2ffd 280w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agentic-rag-output.png?w=560&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=67cd8edf5fac7f5a2d23cc4aadaecd20 560w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agentic-rag-output.png?w=840&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=7c415b76149654aeec54f321e199e5b2 840w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agentic-rag-output.png?w=1100&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=0c7527bf22c7378c2001fba2bbc3ebad 1100w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agentic-rag-output.png?w=1650&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=194746e6bf4e46aaadcf32b8f941a736 1650w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agentic-rag-output.png?w=2500&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=952697cbb31285db207d11a075a2167f 2500w\" />", "summary": "Assembles a LangGraph workflow for a RAG agent, detailing node connections, conditional routing, and graph compilation.", "keywords": ["LangGraph", "StateGraph", "ToolNode", "tools_condition", "retriever_tool", "grade_documents", "rewrite_question", "generate_answer", "generate_query_or_respond", "conditional_edges"]}